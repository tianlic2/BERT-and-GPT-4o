{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ddb1133",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\11527\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (48,58,69,70) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "import re\n",
    "import time\n",
    "\n",
    "# the first six rows are irrelevant to our study\n",
    "first_6_rows = [i for i in range(6)]\n",
    "\n",
    "#Import data\n",
    "data1 = pd.read_csv('01_20210618-20210731.csv',skiprows=first_6_rows)\n",
    "data2 = pd.read_csv('1A_20210801-20210831.csv',skiprows=first_6_rows)\n",
    "data3 = pd.read_csv('01B_20100630-20110430.csv',skiprows=first_6_rows)\n",
    "data4 = pd.read_csv('02_20210429-20210617.csv',skiprows=first_6_rows)\n",
    "data5 = pd.read_csv('2A_20210901-20210930.csv',skiprows=first_6_rows)\n",
    "data6 = pd.read_csv('03_20210306-20210428.csv',skiprows=first_6_rows)\n",
    "data7 = pd.read_csv('04_20210120-20210305.csv',skiprows=first_6_rows)\n",
    "data8 = pd.read_csv('05_20201214-20210119.csv',skiprows=first_6_rows)\n",
    "data9 = pd.read_csv('06_20201203-20201213.csv',skiprows=first_6_rows)\n",
    "data10 = pd.read_csv('07_20201105-20201202.csv',skiprows=first_6_rows)\n",
    "data11 = pd.read_csv('08_20200727-20201104.csv',skiprows=first_6_rows)\n",
    "data12 = pd.read_csv('09_20200508-20200726.csv',skiprows=first_6_rows)\n",
    "data13 = pd.read_csv('10_20200222-20200507.csv',skiprows=first_6_rows)\n",
    "data14 = pd.read_csv('11_20191214-20200221.csv',skiprows=first_6_rows)\n",
    "data15 = pd.read_csv('12_20190926-20191213.csv',skiprows=first_6_rows)\n",
    "data16 = pd.read_csv('13_20190627-20190925.csv',skiprows=first_6_rows)\n",
    "data17 = pd.read_csv('14_20190617-20200626.csv',skiprows=first_6_rows)\n",
    "data18 = pd.read_csv('15_20190404-20190616.csv',skiprows=first_6_rows)\n",
    "data19 = pd.read_csv('16_20190219-20190403.csv',skiprows=first_6_rows)\n",
    "data20 = pd.read_csv('17_20181129-20210218.csv',skiprows=first_6_rows)\n",
    "data21 = pd.read_csv('18_20180914-20181128.csv',skiprows=first_6_rows)\n",
    "data22 = pd.read_csv('19_20180628-20180913.csv',skiprows=first_6_rows)\n",
    "data23 = pd.read_csv('20_20180325-20180627.csv',skiprows=first_6_rows)\n",
    "data24 = pd.read_csv('21_20180131-20180324.csv',skiprows=first_6_rows)\n",
    "data25 = pd.read_csv('22_20170930-20180130.csv',skiprows=first_6_rows)\n",
    "data26 = pd.read_csv('23_20170704-20170929.csv',skiprows=first_6_rows)\n",
    "data27 = pd.read_csv('24_20170219-20170703.csv',skiprows=first_6_rows)\n",
    "data28 = pd.read_csv('25_20160715-20170218.csv',skiprows=first_6_rows)\n",
    "data29 = pd.read_csv('26_20160129-20160714.csv',skiprows=first_6_rows)\n",
    "data30 = pd.read_csv('27_20150314-20160128.csv',skiprows=first_6_rows)\n",
    "data31 = pd.read_csv('28_20130813-20150313.csv',skiprows=first_6_rows)\n",
    "data32 = pd.read_csv('29_20130516-20130812.csv',skiprows=first_6_rows)\n",
    "data33 = pd.read_csv('30_20110901-20130515.csv',skiprows=first_6_rows)\n",
    "data34 = pd.read_csv('31_20110501-20110831.csv',skiprows=first_6_rows)\n",
    "data35 = pd.read_csv('5A_20211201-20211231.csv',skiprows=first_6_rows)\n",
    "data36 = pd.read_csv('4A_20211101-20211130.csv',skiprows=first_6_rows)\n",
    "data37 = pd.read_csv('3A_20211001-20211031.csv',skiprows=first_6_rows)\n",
    "data38 = pd.read_csv('9A_20220610-20220710.csv',skiprows=first_6_rows)\n",
    "data39 = pd.read_csv('10A_20220711-20220729.csv',skiprows=first_6_rows)\n",
    "data40 = pd.read_csv('11A_20220730-20221006.csv',skiprows=first_6_rows)\n",
    "data41 = pd.read_csv('12A_20221007-20221116.csv',skiprows=first_6_rows)\n",
    "data42 = pd.read_csv('13A_20221117.csv',skiprows=first_6_rows)\n",
    "data43 = pd.read_csv('14A_20221123-20221130.csv',skiprows=first_6_rows)\n",
    "data44 = pd.read_csv('15A_20221118-20221120.csv',skiprows=first_6_rows)\n",
    "data45 = pd.read_csv('16A_20221121-20221122.csv',skiprows=first_6_rows)\n",
    "data46 = pd.read_csv('6A_20220101-20220227.csv',skiprows=first_6_rows)\n",
    "data47 = pd.read_csv('7A_20220228-20220424.csv',skiprows=first_6_rows)\n",
    "data48 = pd.read_csv('8A_202204225-20220609.csv',skiprows=first_6_rows)\n",
    "data49 = pd.read_csv('17A_20221201-20221231.csv',skiprows=first_6_rows)\n",
    "\n",
    "#data35, data36, and data37 have 5 or 6 more columns than other files.\n",
    "\n",
    "data35 = data35.drop(columns=['Entity Info','Reddit Author Awardee Karma', 'Reddit Author Awarder Karma',\n",
    "'Reddit Author Karma','Subreddit','Subreddit Subscribers'])\n",
    "data36 = data36.drop(columns=['Reddit Author Awardee Karma', 'Reddit Author Awarder Karma',\n",
    "'Reddit Author Karma','Subreddit','Subreddit Subscribers'])\n",
    "data37 = data37.drop(columns=['Reddit Author Awardee Karma', 'Reddit Author Awarder Karma',\n",
    "'Reddit Author Karma','Subreddit','Subreddit Subscribers'])\n",
    "data38 = data38.drop(columns=['Twitter Likes','Air Type','Broadcast Media Url','Broadcast Type',\n",
    "                               'Content Source','Content Source','Content Source Name','Entity Info',\n",
    "                               'Is Syndicated','Media Type','Reddit Author Awardee Karma',\n",
    "                               'Reddit Author Awarder Karma','Reddit Comments','Reddit Score Upvote Ratio',\n",
    "                               'Subreddit','Subreddit Subscribers','Reddit Author Karma'])\n",
    "\n",
    "data39 = data39.drop(columns=['Twitter Likes','Air Type','Broadcast Media Url','Broadcast Type',\n",
    "                               'Content Source','Content Source','Content Source Name','Entity Info',\n",
    "                               'Is Syndicated','Media Type','Reddit Author Awardee Karma',\n",
    "                               'Reddit Author Awarder Karma','Reddit Comments','Reddit Score Upvote Ratio',\n",
    "                               'Subreddit','Subreddit Subscribers','Reddit Author Karma'])\n",
    "\n",
    "data40 = data40.drop(columns=['Twitter Likes','Air Type','Broadcast Media Url','Broadcast Type',\n",
    "                               'Content Source','Content Source','Content Source Name','Entity Info',\n",
    "                               'Is Syndicated','Media Type','Reddit Author Awardee Karma',\n",
    "                               'Reddit Author Awarder Karma','Reddit Comments','Reddit Score Upvote Ratio',\n",
    "                               'Subreddit','Subreddit Subscribers','Reddit Author Karma'])\n",
    "\n",
    "data41 = data41.drop(columns=['Twitter Likes','Air Type','Broadcast Media Url','Broadcast Type',\n",
    "                               'Content Source','Content Source','Content Source Name','Entity Info',\n",
    "                               'Is Syndicated','Media Type','Reddit Author Awardee Karma',\n",
    "                               'Reddit Author Awarder Karma','Reddit Comments','Reddit Score Upvote Ratio',\n",
    "                               'Subreddit','Subreddit Subscribers','Reddit Author Karma'])\n",
    "data42 = data42.drop(columns=['Twitter Likes','Air Type','Broadcast Media Url','Broadcast Type',\n",
    "                               'Content Source','Content Source','Content Source Name','Entity Info',\n",
    "                               'Is Syndicated','Media Type','Reddit Author Awardee Karma',\n",
    "                               'Reddit Author Awarder Karma','Reddit Comments','Reddit Score Upvote Ratio',\n",
    "                               'Subreddit','Subreddit Subscribers','Reddit Author Karma'])\n",
    "data43 = data43.drop(columns=['Twitter Likes','Air Type','Broadcast Media Url','Broadcast Type',\n",
    "                               'Content Source','Content Source','Content Source Name','Entity Info',\n",
    "                               'Is Syndicated','Media Type','Reddit Author Awardee Karma',\n",
    "                               'Reddit Author Awarder Karma','Reddit Comments','Reddit Score Upvote Ratio',\n",
    "                               'Subreddit','Subreddit Subscribers','Reddit Author Karma'])\n",
    "data44 = data44.drop(columns=['Twitter Likes','Air Type','Broadcast Media Url','Broadcast Type',\n",
    "                               'Content Source','Content Source','Content Source Name','Entity Info',\n",
    "                               'Is Syndicated','Media Type','Reddit Author Awardee Karma',\n",
    "                               'Reddit Author Awarder Karma','Reddit Comments','Reddit Score Upvote Ratio',\n",
    "                               'Subreddit','Subreddit Subscribers','Reddit Author Karma'])\n",
    "data45 = data45.drop(columns=['Twitter Likes','Air Type','Broadcast Media Url','Broadcast Type',\n",
    "                               'Content Source','Content Source','Content Source Name','Entity Info',\n",
    "                               'Is Syndicated','Media Type','Reddit Author Awardee Karma',\n",
    "                               'Reddit Author Awarder Karma','Reddit Comments','Reddit Score Upvote Ratio',\n",
    "                               'Subreddit','Subreddit Subscribers','Reddit Author Karma'])\n",
    "\n",
    "data46 = data46.drop(columns=['Twitter Likes','Air Type','Broadcast Media Url','Broadcast Type',\n",
    "                               'Content Source','Content Source','Content Source Name','Entity Info',\n",
    "                               'Is Syndicated','Media Type','Reddit Author Awardee Karma',\n",
    "                               'Reddit Author Awarder Karma','Reddit Comments','Reddit Score Upvote Ratio',\n",
    "                               'Subreddit','Subreddit Subscribers','Reddit Author Karma'])\n",
    "\n",
    "data47 = data47.drop(columns=['Twitter Likes','Air Type','Broadcast Media Url','Broadcast Type',\n",
    "                               'Content Source','Content Source','Content Source Name','Entity Info',\n",
    "                               'Is Syndicated','Media Type','Reddit Author Awardee Karma',\n",
    "                               'Reddit Author Awarder Karma','Reddit Comments','Reddit Score Upvote Ratio',\n",
    "                               'Subreddit','Subreddit Subscribers','Reddit Author Karma'])\n",
    "\n",
    "data48 = data48.drop(columns=['Twitter Likes','Air Type','Broadcast Media Url','Broadcast Type',\n",
    "                               'Content Source','Content Source','Content Source Name','Entity Info',\n",
    "                               'Is Syndicated','Media Type','Reddit Author Awardee Karma',\n",
    "                               'Reddit Author Awarder Karma','Reddit Comments','Reddit Score Upvote Ratio',\n",
    "                               'Subreddit','Subreddit Subscribers','Reddit Author Karma'])\n",
    "\n",
    "data49 = data49.drop(columns=['Twitter Likes','Air Type','Broadcast Media Url','Broadcast Type',\n",
    "                               'Content Source','Content Source','Content Source Name','Entity Info',\n",
    "                               'Is Syndicated','Media Type','Reddit Author Awardee Karma',\n",
    "                               'Reddit Author Awarder Karma','Reddit Comments','Reddit Score Upvote Ratio',\n",
    "                               'Subreddit','Subreddit Subscribers','Reddit Author Karma'])\n",
    "\n",
    "\n",
    "alldata = [data1,data2,data3,data4,data5,data6,data7,data8,data9,data10,data11,data12,data13,\n",
    "           data14,data15,data16,data17,data18,data19,data20,data21,data22,data23,data24,data25,\n",
    "           data26,data27,data28,data29,data30,data31,data32,data33,data34,data35,data36,data37,\n",
    "          data38,data39,data40,data41,data42,data43,data44,data45,data46,data47,data48,data49]\n",
    "\n",
    "\n",
    "dataset_all = pd.concat(alldata,ignore_index=True)\n",
    "dataset_all.sort_values(\"Date\",inplace=True)\n",
    "dataset_all = dataset_all.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "930fa968",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\11527\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset_all\n",
    "#preprocessing for label\n",
    "import nltk\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "b = []\n",
    "for i,u in dataset.iterrows():\n",
    "    a = []\n",
    "    word =''\n",
    "    for words in str(u['Full Text']).split(): #tokenization\n",
    "        if 1: #remove @users\n",
    "            words = words.replace('#',' ') #remove hashtag symbol\n",
    "            words = words.replace('»ß','a')\n",
    "            words = re.sub(r'[^a-zA-Z]', ' ', words)\n",
    "            if '#' not in words:\n",
    "                #if 'http:' not in words:\n",
    "                if 'http:' not in words:#remove URLs\n",
    "                    if 1 : #remove symbol\n",
    "                        #if len(words)>1:\n",
    "                        word += (words+' ')\n",
    "    doc = ''\n",
    "    for token in word.split():\n",
    "        #if len(token) >1: # remove words that have less than 1 characters\n",
    "        token = token.lower()# lowercase form\n",
    "        token = lemmatizer.lemmatize(token) #lemmatization\n",
    "        doc += (token+' ')\n",
    "    b.append(doc)\n",
    "dataset['processed for label']=[i for i in b]\n",
    "\n",
    "\n",
    "label_1_index = []\n",
    "label_2_index = []\n",
    "label_3_index = []\n",
    "label_4_index = []\n",
    "label_5_index = []\n",
    "index = []\n",
    "for i,v in dataset.iterrows():\n",
    "    #print(v['processed for label'])\n",
    "    if  \"in vitro meat\" in v['processed for label'] or 'invitromeat' in v['processed for label'] or 'invitro meat' in v['processed for label']:\n",
    "        label_1_index.append(i)\n",
    "        #print(1)\n",
    "    elif  \"cell based meat\" in v['processed for label'] or 'cellbasedmeat' in v['processed for label'] or 'cellbased meat' in v['processed for label']:\n",
    "        label_2_index.append(i)\n",
    "        #print(2)\n",
    "    elif \"cultivated meat\" in v['processed for label'] or 'cultivatedmeat'  in v['processed for label']:\n",
    "        label_3_index.append(i)\n",
    "        #print(3)\n",
    "    elif \"cultured meat\" in v['processed for label'] or 'culturedmeat' in v['processed for label']:\n",
    "        label_4_index.append(i)\n",
    "        #print(4)\n",
    "    elif \"lab grown meat\" in v['processed for label'] or 'labgrownmeat' in v['processed for label'] or 'labgrown meat' in v['processed for label']:\n",
    "        label_5_index.append(i)\n",
    "        #print(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "288aa67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.loc[label_1_index,'label'] = 1\n",
    "dataset.loc[label_2_index,'label'] = 2\n",
    "dataset.loc[label_3_index,'label'] = 3\n",
    "dataset.loc[label_4_index,'label'] = 4\n",
    "dataset.loc[label_5_index,'label'] = 5\n",
    "\n",
    "year = []\n",
    "for i,v in dataset.iterrows():\n",
    "    year.append(v['Date'][:4])\n",
    "dataset['Year'] = [i for i in year]\n",
    "\n",
    "day = []\n",
    "for i, v in dataset.iterrows():\n",
    "    day.append(v['Date'][:10])\n",
    "dataset['Day'] = [i for i in day]\n",
    "\n",
    "month = []\n",
    "for i, v in dataset.iterrows():\n",
    "    month.append(v['Date'][:7])\n",
    "dataset['Month'] = [i for i in month]\n",
    "\n",
    "containlabel = dataset.loc[(dataset['label']==1)|(dataset['label']==2)|(dataset['label']==3)|(dataset['label']==4)|\n",
    "                          (dataset['label']==5)]\n",
    "\n",
    "\n",
    "containlabel = containlabel.drop_duplicates(subset='Full Text', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c14485a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(231777, 104)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "containlabel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86682680",
   "metadata": {},
   "outputs": [],
   "source": [
    "containlabel.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90d14f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "containlabel['Tweet'] = containlabel['Full Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59adbf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88d7b878",
   "metadata": {},
   "outputs": [],
   "source": [
    "Paris_1 = pd.read_csv('Coding_Paris_Week1.csv')\n",
    "Paris_2 = pd.read_csv('Coding_Paris_Week2.csv')\n",
    "Paris_3 = pd.read_csv('Coding_Paris_Week3.csv')\n",
    "Paris_4 = pd.read_csv('Coding_Paris_Week4.csv')\n",
    "Paris_5 = pd.read_csv('Coding_Paris_Week5.csv')\n",
    "Shawn_1 = pd.read_csv('Coding_Shawn_Week1.csv')\n",
    "Shawn_2 = pd.read_csv('Coding_Shawn_Week2.csv')\n",
    "Shawn_3 = pd.read_csv('Coding_Shawn_Week3.csv')\n",
    "Shawn_4 = pd.read_csv('Coding_Shawn_Week4.csv')\n",
    "Shawn_5 = pd.read_csv('Coding_Shawn_Week5.csv')\n",
    "Tianli_1 = pd.read_csv('Coding_Tianli_Week1.csv')\n",
    "Tianli_2 = pd.read_csv('Coding_Tianli_Week2.csv')\n",
    "Tianli_3 = pd.read_csv('Coding_Tianli_Week3.csv')\n",
    "Tianli_4 = pd.read_csv('Coding_Tianli_Week4.csv')\n",
    "Tianli_5 = pd.read_csv('Coding_Tianli_Week5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b43d68c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @biancale_monash ATTN: Aus women interested...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The future will be full of lab grown meat: htt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Future Of Meat: 45 In Vitro Meat Recipes Y...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Some makers of lab-grown meat have adopted a c...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lab grown meat doesn‚Äôt sit well with me</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22970</th>\n",
       "      <td>I've unexpectedly ended up with David Lewis on...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22971</th>\n",
       "      <td>cheap cultivated meat https://t.co/hsXLscDaVS</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22972</th>\n",
       "      <td>@BobsBlog I mean to be clear, it depends exact...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22973</th>\n",
       "      <td>The market for cultured meat is no joke (prese...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22974</th>\n",
       "      <td>@guardiannews LAB-GROWN MEAT HITS A MAJOR MILE...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22975 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Tweet  Sentiment\n",
       "0      RT @biancale_monash ATTN: Aus women interested...          3\n",
       "1      The future will be full of lab grown meat: htt...          1\n",
       "2      The Future Of Meat: 45 In Vitro Meat Recipes Y...          4\n",
       "3      Some makers of lab-grown meat have adopted a c...          3\n",
       "4                Lab grown meat doesn‚Äôt sit well with me          2\n",
       "...                                                  ...        ...\n",
       "22970  I've unexpectedly ended up with David Lewis on...          3\n",
       "22971      cheap cultivated meat https://t.co/hsXLscDaVS          3\n",
       "22972  @BobsBlog I mean to be clear, it depends exact...          3\n",
       "22973  The market for cultured meat is no joke (prese...          3\n",
       "22974  @guardiannews LAB-GROWN MEAT HITS A MAJOR MILE...          3\n",
       "\n",
       "[22975 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine all the data frames into one\n",
    "combined_df = pd.concat([\n",
    "    Paris_1, Paris_2, Paris_3, Paris_4, Paris_5,\n",
    "    Shawn_1, Shawn_2, Shawn_3, Shawn_4, Shawn_5,\n",
    "    Tianli_1, Tianli_2, Tianli_3, Tianli_4, Tianli_5\n",
    "], ignore_index=True)\n",
    "\n",
    "combined_df['Sentiment'] = combined_df['Sentiment'].astype(int)\n",
    "\n",
    "\n",
    "\n",
    "# Check the combined data frame\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "884db7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = combined_df.sample(frac=0.8,random_state=2024)\n",
    "\n",
    "validation_df = combined_df.drop(train_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a547ade7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16487</th>\n",
       "      <td>'Cultured meat' could spell end of traditional...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14558</th>\n",
       "      <td>Lab-grown meat is here ‚Äì but will vegetarians ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1756</th>\n",
       "      <td>RT @GoodFoodScience Did you miss last week's S...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7209</th>\n",
       "      <td>Home grown hamburgers? Ew!! - Is 'in vitro mea...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>50 years from now, real meat will be a luxury ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5067</th>\n",
       "      <td>@Yea3601 @ItsMeChase1 @ShotgunWillard @unusual...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>RT @NinesCatudio So, would you eat cultivated ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9590</th>\n",
       "      <td>Finally a dream comes true: in-vitro-meat aka ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12755</th>\n",
       "      <td>Lab grown meat !!! Oh my its making my tummy t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11708</th>\n",
       "      <td>Could lab-grown meat soon be the solution to t...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18380 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Tweet  Sentiment\n",
       "16487  'Cultured meat' could spell end of traditional...          1\n",
       "14558  Lab-grown meat is here ‚Äì but will vegetarians ...          3\n",
       "1756   RT @GoodFoodScience Did you miss last week's S...          3\n",
       "7209   Home grown hamburgers? Ew!! - Is 'in vitro mea...          2\n",
       "317    50 years from now, real meat will be a luxury ...          1\n",
       "...                                                  ...        ...\n",
       "5067   @Yea3601 @ItsMeChase1 @ShotgunWillard @unusual...          2\n",
       "878    RT @NinesCatudio So, would you eat cultivated ...          3\n",
       "9590   Finally a dream comes true: in-vitro-meat aka ...          1\n",
       "12755  Lab grown meat !!! Oh my its making my tummy t...          1\n",
       "11708  Could lab-grown meat soon be the solution to t...          3\n",
       "\n",
       "[18380 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7c4ac1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>@csimpsyo @Tbogin @jonlovett Cultured meat</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RT @ndonyourtable What's the difference betwee...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>#Technology #Tech Lab-Grown Meat Is Coming htt...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>This year is the first time cultivated meat ha...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>RT @NewHarvestOrg üçóand @UmaValeti, who co-foun...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22951</th>\n",
       "      <td>@Joseph_Plant What goes into lab grown meat? I...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22955</th>\n",
       "      <td>Google Funding Lab Grown Meat‚Ä¶ No Animals Kill...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22958</th>\n",
       "      <td>RT @Orbyne #LSEForum cultured meat avoids the ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22969</th>\n",
       "      <td>@MusadADroid @AuthorGusPegel The answer would ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22974</th>\n",
       "      <td>@guardiannews LAB-GROWN MEAT HITS A MAJOR MILE...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4595 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Tweet  Sentiment\n",
       "10            @csimpsyo @Tbogin @jonlovett Cultured meat          3\n",
       "13     RT @ndonyourtable What's the difference betwee...          3\n",
       "14     #Technology #Tech Lab-Grown Meat Is Coming htt...          3\n",
       "21     This year is the first time cultivated meat ha...          3\n",
       "34     RT @NewHarvestOrg üçóand @UmaValeti, who co-foun...          3\n",
       "...                                                  ...        ...\n",
       "22951  @Joseph_Plant What goes into lab grown meat? I...          2\n",
       "22955  Google Funding Lab Grown Meat‚Ä¶ No Animals Kill...          1\n",
       "22958  RT @Orbyne #LSEForum cultured meat avoids the ...          1\n",
       "22969  @MusadADroid @AuthorGusPegel The answer would ...          4\n",
       "22974  @guardiannews LAB-GROWN MEAT HITS A MAJOR MILE...          3\n",
       "\n",
       "[4595 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19016511",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./sentiment_model\\\\tokenizer_config.json',\n",
       " './sentiment_model\\\\special_tokens_map.json',\n",
       " './sentiment_model\\\\vocab.txt',\n",
       " './sentiment_model\\\\added_tokens.json')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1.Load the data\n",
    "\n",
    "# Adjust labels from 1-4 to 0-3\n",
    "train_tweets = train_df['Tweet'].tolist()\n",
    "train_labels = [label - 1 for label in train_df['Sentiment'].tolist()]\n",
    "\n",
    "val_tweets = validation_df['Tweet'].tolist()\n",
    "val_labels = [label - 1 for label in validation_df['Sentiment'].tolist()]\n",
    "\n",
    "# 2. Define a custom dataset\n",
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, tweets, labels, tokenizer, max_len):\n",
    "        self.tweets = tweets\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tweets)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        tweet = str(self.tweets[item])\n",
    "        label = self.labels[item]\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            tweet,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        return {\n",
    "            'tweet_text': tweet,\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# 3. Prepare the datasets and dataloaders\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "MAX_LEN = 128\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 3\n",
    "\n",
    "train_dataset = SentimentDataset(\n",
    "    tweets=train_tweets, labels=train_labels, tokenizer=tokenizer, max_len=MAX_LEN)\n",
    "val_dataset = SentimentDataset(\n",
    "    tweets=val_tweets, labels=val_labels, tokenizer=tokenizer, max_len=MAX_LEN)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# 4. Load the BERT model\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=4)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# 5. Define optimizer, scheduler, and loss function\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "total_steps = len(train_loader) * EPOCHS\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=0, num_training_steps=total_steps\n",
    ")\n",
    "loss_fn = torch.nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "# 6. Train the model\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "\n",
    "# 7. Save the model\n",
    "model.save_pretrained(\"./sentiment_model\")\n",
    "tokenizer.save_pretrained(\"./sentiment_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1501292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>@csimpsyo @Tbogin @jonlovett Cultured meat</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RT @ndonyourtable What's the difference betwee...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>#Technology #Tech Lab-Grown Meat Is Coming htt...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>This year is the first time cultivated meat ha...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>RT @NewHarvestOrg üçóand @UmaValeti, who co-foun...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22951</th>\n",
       "      <td>@Joseph_Plant What goes into lab grown meat? I...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22955</th>\n",
       "      <td>Google Funding Lab Grown Meat‚Ä¶ No Animals Kill...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22958</th>\n",
       "      <td>RT @Orbyne #LSEForum cultured meat avoids the ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22969</th>\n",
       "      <td>@MusadADroid @AuthorGusPegel The answer would ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22974</th>\n",
       "      <td>@guardiannews LAB-GROWN MEAT HITS A MAJOR MILE...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4595 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Tweet  Sentiment\n",
       "10            @csimpsyo @Tbogin @jonlovett Cultured meat          3\n",
       "13     RT @ndonyourtable What's the difference betwee...          3\n",
       "14     #Technology #Tech Lab-Grown Meat Is Coming htt...          3\n",
       "21     This year is the first time cultivated meat ha...          3\n",
       "34     RT @NewHarvestOrg üçóand @UmaValeti, who co-foun...          3\n",
       "...                                                  ...        ...\n",
       "22951  @Joseph_Plant What goes into lab grown meat? I...          2\n",
       "22955  Google Funding Lab Grown Meat‚Ä¶ No Animals Kill...          1\n",
       "22958  RT @Orbyne #LSEForum cultured meat avoids the ...          1\n",
       "22969  @MusadADroid @AuthorGusPegel The answer would ...          4\n",
       "22974  @guardiannews LAB-GROWN MEAT HITS A MAJOR MILE...          3\n",
       "\n",
       "[4595 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bbb548ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7867\n",
      "Weighted Precision: 0.7904\n",
      "Weighted Recall: 0.7867\n",
      "Weighted F1 Score: 0.7871\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6507    0.7528    0.6980      1084\n",
      "           1     0.6150    0.6179    0.6165       424\n",
      "           2     0.8822    0.8435    0.8624      2984\n",
      "           3     0.3226    0.1942    0.2424       103\n",
      "\n",
      "    accuracy                         0.7867      4595\n",
      "   macro avg     0.6176    0.6021    0.6048      4595\n",
      "weighted avg     0.7904    0.7867    0.7871      4595\n",
      "\n",
      "Predictions have been saved to 'bert_validation_predictions_with_tweets.csv'\n"
     ]
    }
   ],
   "source": [
    "# 1. Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "# 2. Define the evaluation function\n",
    "def evaluate_model(model, data_loader):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    input_texts = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            tweets = batch[\"tweet_text\"]  # Assuming 'text' is the key containing the tweet text\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            _, preds = torch.max(logits, dim=1)\n",
    "\n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "            input_texts.extend(tweets)  # Add the input text\n",
    "\n",
    "    return input_texts, true_labels, predictions\n",
    "\n",
    "# 3. Evaluate the model on the validation set\n",
    "val_input_texts, val_true_labels, val_predictions = evaluate_model(model, val_loader)\n",
    "\n",
    "# 4. Calculate evaluation metrics\n",
    "accuracy = accuracy_score(val_true_labels, val_predictions)\n",
    "weighted_precision = precision_score(val_true_labels, val_predictions, average='weighted')\n",
    "weighted_recall = recall_score(val_true_labels, val_predictions, average='weighted')\n",
    "weighted_f1 = f1_score(val_true_labels, val_predictions, average='weighted')\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Weighted Precision: {weighted_precision:.4f}')\n",
    "print(f'Weighted Recall: {weighted_recall:.4f}')\n",
    "print(f'Weighted F1 Score: {weighted_f1:.4f}')\n",
    "\n",
    "# 5. Display the classification report\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(val_true_labels, val_predictions, digits=4))\n",
    "\n",
    "# 6. Create and save the DataFrame\n",
    "results_df = pd.DataFrame({\n",
    "    'Tweet': val_input_texts,\n",
    "    'True Label': val_true_labels,\n",
    "    'Predicted Label': val_predictions\n",
    "})\n",
    "\n",
    "# Save as a CSV file\n",
    "results_df.to_csv('bert_validation_predictions_with_tweets.csv', index=False)\n",
    "print(\"Predictions have been saved to 'bert_validation_predictions_with_tweets.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fc9faf19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>True Label</th>\n",
       "      <th>Predicted Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@csimpsyo @Tbogin @jonlovett Cultured meat</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @ndonyourtable What's the difference betwee...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#Technology #Tech Lab-Grown Meat Is Coming htt...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This year is the first time cultivated meat ha...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @NewHarvestOrg üçóand @UmaValeti, who co-foun...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4590</th>\n",
       "      <td>@Joseph_Plant What goes into lab grown meat? I...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4591</th>\n",
       "      <td>Google Funding Lab Grown Meat‚Ä¶ No Animals Kill...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4592</th>\n",
       "      <td>RT @Orbyne #LSEForum cultured meat avoids the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4593</th>\n",
       "      <td>@MusadADroid @AuthorGusPegel The answer would ...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4594</th>\n",
       "      <td>@guardiannews LAB-GROWN MEAT HITS A MAJOR MILE...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4595 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Tweet  True Label  \\\n",
       "0            @csimpsyo @Tbogin @jonlovett Cultured meat           2   \n",
       "1     RT @ndonyourtable What's the difference betwee...           2   \n",
       "2     #Technology #Tech Lab-Grown Meat Is Coming htt...           2   \n",
       "3     This year is the first time cultivated meat ha...           2   \n",
       "4     RT @NewHarvestOrg üçóand @UmaValeti, who co-foun...           2   \n",
       "...                                                 ...         ...   \n",
       "4590  @Joseph_Plant What goes into lab grown meat? I...           1   \n",
       "4591  Google Funding Lab Grown Meat‚Ä¶ No Animals Kill...           0   \n",
       "4592  RT @Orbyne #LSEForum cultured meat avoids the ...           0   \n",
       "4593  @MusadADroid @AuthorGusPegel The answer would ...           3   \n",
       "4594  @guardiannews LAB-GROWN MEAT HITS A MAJOR MILE...           2   \n",
       "\n",
       "      Predicted Label  \n",
       "0                   2  \n",
       "1                   2  \n",
       "2                   2  \n",
       "3                   2  \n",
       "4                   2  \n",
       "...               ...  \n",
       "4590                1  \n",
       "4591                0  \n",
       "4592                0  \n",
       "4593                0  \n",
       "4594                2  \n",
       "\n",
       "[4595 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
